{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/mike/Documents/programming/mybot/mybotenv/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# to load dataset as datafrae\n",
    "import pandas as pd\n",
    "# for columns\n",
    "import ast \n",
    "# MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# split train and test\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answers</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>target</th>\n",
       "      <th>sent_emb</th>\n",
       "      <th>quest_emb</th>\n",
       "      <th>cosine_sim</th>\n",
       "      <th>euclidean_dis</th>\n",
       "      <th>pred_idx_cos</th>\n",
       "      <th>pred_idx_euc</th>\n",
       "      <th>root_match_idx</th>\n",
       "      <th>root_match_idx_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>269</td>\n",
       "      <td>yes</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>['Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/...</td>\n",
       "      <td>1</td>\n",
       "      <td>[array([0.03037658, 0.04433101, 0.08135635, .....</td>\n",
       "      <td>[[0.01491953 0.02197376 0.02136409 ... 0.01360...</td>\n",
       "      <td>[0.1401391625404358, 0.11776834726333618, 0.09...</td>\n",
       "      <td>[2.8352642, 2.4563262, 1.5417788, 2.9730926]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>207</td>\n",
       "      <td>yes</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>['Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/...</td>\n",
       "      <td>1</td>\n",
       "      <td>[array([0.03037658, 0.04433101, 0.08135635, .....</td>\n",
       "      <td>[[0.04444952 0.02800576 0.03035772 ... 0.02242...</td>\n",
       "      <td>[0.12254136800765991, 0.08665323257446289, 0.0...</td>\n",
       "      <td>[2.396976, 1.7860672, 1.1152366, 2.3845947]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>526</td>\n",
       "      <td>yes</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>2003</td>\n",
       "      <td>['Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/...</td>\n",
       "      <td>3</td>\n",
       "      <td>[array([0.03037658, 0.04433101, 0.08135635, .....</td>\n",
       "      <td>[[0.03949683 0.04509903 0.01808935 ... 0.04610...</td>\n",
       "      <td>[0.09432470798492432, 0.06841456890106201, 0.0...</td>\n",
       "      <td>[1.8688717, 1.4023948, 1.0954475, 1.7620108]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>166</td>\n",
       "      <td>yes</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>['Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/...</td>\n",
       "      <td>1</td>\n",
       "      <td>[array([0.03037658, 0.04433101, 0.08135635, .....</td>\n",
       "      <td>[[0.03284301 0.01849968 0.02034627 ... 0.02206...</td>\n",
       "      <td>[0.1274968981742859, 0.09279131889343262, 0.08...</td>\n",
       "      <td>[2.4843664, 1.894182, 1.2221413, 2.5239604]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276</td>\n",
       "      <td>yes</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>['Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/...</td>\n",
       "      <td>1</td>\n",
       "      <td>[array([0.03037658, 0.04433101, 0.08135635, .....</td>\n",
       "      <td>[[0.03003643 0.01056742 0.01999657 ... 0.01232...</td>\n",
       "      <td>[0.12346065044403076, 0.10314065217971802, 0.0...</td>\n",
       "      <td>[2.5265627, 2.172618, 1.3479614, 2.6632156]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_start answers                                            context  \\\n",
       "0           269     yes  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "1           207     yes  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "2           526     yes  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "3           166     yes  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "4           276     yes  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "\n",
       "                                            question                 text  \\\n",
       "0           When did Beyonce start becoming popular?    in the late 1990s   \n",
       "1  What areas did Beyonce compete in when she was...  singing and dancing   \n",
       "2  When did Beyonce leave Destiny's Child and bec...                 2003   \n",
       "3      In what city and state did Beyonce  grow up?        Houston, Texas   \n",
       "4         In which decade did Beyonce become famous?           late 1990s   \n",
       "\n",
       "                                           sentences  target  \\\n",
       "0  ['Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/...       1   \n",
       "1  ['Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/...       1   \n",
       "2  ['Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/...       3   \n",
       "3  ['Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/...       1   \n",
       "4  ['Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/...       1   \n",
       "\n",
       "                                            sent_emb  \\\n",
       "0  [array([0.03037658, 0.04433101, 0.08135635, .....   \n",
       "1  [array([0.03037658, 0.04433101, 0.08135635, .....   \n",
       "2  [array([0.03037658, 0.04433101, 0.08135635, .....   \n",
       "3  [array([0.03037658, 0.04433101, 0.08135635, .....   \n",
       "4  [array([0.03037658, 0.04433101, 0.08135635, .....   \n",
       "\n",
       "                                           quest_emb  \\\n",
       "0  [[0.01491953 0.02197376 0.02136409 ... 0.01360...   \n",
       "1  [[0.04444952 0.02800576 0.03035772 ... 0.02242...   \n",
       "2  [[0.03949683 0.04509903 0.01808935 ... 0.04610...   \n",
       "3  [[0.03284301 0.01849968 0.02034627 ... 0.02206...   \n",
       "4  [[0.03003643 0.01056742 0.01999657 ... 0.01232...   \n",
       "\n",
       "                                          cosine_sim  \\\n",
       "0  [0.1401391625404358, 0.11776834726333618, 0.09...   \n",
       "1  [0.12254136800765991, 0.08665323257446289, 0.0...   \n",
       "2  [0.09432470798492432, 0.06841456890106201, 0.0...   \n",
       "3  [0.1274968981742859, 0.09279131889343262, 0.08...   \n",
       "4  [0.12346065044403076, 0.10314065217971802, 0.0...   \n",
       "\n",
       "                                  euclidean_dis  pred_idx_cos  pred_idx_euc  \\\n",
       "0  [2.8352642, 2.4563262, 1.5417788, 2.9730926]             2             2   \n",
       "1   [2.396976, 1.7860672, 1.1152366, 2.3845947]             2             2   \n",
       "2  [1.8688717, 1.4023948, 1.0954475, 1.7620108]             1             2   \n",
       "3   [2.4843664, 1.894182, 1.2221413, 2.5239604]             2             2   \n",
       "4   [2.5265627, 2.172618, 1.3479614, 2.6632156]             2             2   \n",
       "\n",
       "  root_match_idx  root_match_idx_first  \n",
       "0             []                    -1  \n",
       "1             []                    -1  \n",
       "2             []                    -1  \n",
       "3             []                    -1  \n",
       "4             []                    -1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pima indians dataset\n",
    "dataset = pd.read_csv(\"train_detect_sent.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[dataset[\"sentences\"].apply(lambda x: len(ast.literal_eval(x)))<11].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(data):\n",
    "    train = pd.DataFrame()\n",
    "     \n",
    "    for k in range(len(data[\"euclidean_dis\"])):\n",
    "        dis = ast.literal_eval(data[\"euclidean_dis\"][k])\n",
    "        for i in range(len(dis)):\n",
    "            train.loc[k, \"column_euc_\"+\"%s\"%i] = dis[i]\n",
    "    \n",
    "    print(\"Finished euclidean_dis\")\n",
    "    \n",
    "    for k in range(len(data[\"cosine_sim\"])):\n",
    "        dis = ast.literal_eval(data[\"cosine_sim\"][k].replace(\"nan\",\"1\"))\n",
    "        for i in range(len(dis)):\n",
    "            train.loc[k, \"column_cos_\"+\"%s\"%i] = dis[i]\n",
    "            \n",
    "    train[\"target\"] = data[\"target\"]\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished euclidean_dis\n"
     ]
    }
   ],
   "source": [
    "train = create_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column_euc_0    8.966061\n",
       "column_euc_1    8.182969\n",
       "column_euc_2    8.952271\n",
       "column_euc_3    8.043482\n",
       "column_euc_4         NaN\n",
       "column_euc_5         NaN\n",
       "column_euc_6         NaN\n",
       "column_euc_7         NaN\n",
       "column_euc_8         NaN\n",
       "column_euc_9         NaN\n",
       "column_cos_0    1.000000\n",
       "column_cos_1    1.000000\n",
       "column_cos_2    1.000000\n",
       "column_cos_3    1.000000\n",
       "column_cos_4         NaN\n",
       "column_cos_5         NaN\n",
       "column_cos_6         NaN\n",
       "column_cos_7         NaN\n",
       "column_cos_8         NaN\n",
       "column_cos_9         NaN\n",
       "target          9.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.apply(max, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset1 = train.iloc[:,:10].fillna(60)\n",
    "subset2 = train.iloc[:,10:].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = pd.concat([subset1, subset2],axis=1, join_axes=[subset1.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column_euc_0     8.966061\n",
       "column_euc_1    60.000000\n",
       "column_euc_2    60.000000\n",
       "column_euc_3    60.000000\n",
       "column_euc_4    60.000000\n",
       "column_euc_5    60.000000\n",
       "column_euc_6    60.000000\n",
       "column_euc_7    60.000000\n",
       "column_euc_8    60.000000\n",
       "column_euc_9    60.000000\n",
       "column_cos_0     1.000000\n",
       "column_cos_1     1.000000\n",
       "column_cos_2     1.000000\n",
       "column_cos_3     1.000000\n",
       "column_cos_4     1.000000\n",
       "column_cos_5     1.000000\n",
       "column_cos_6     1.000000\n",
       "column_cos_7     1.000000\n",
       "column_cos_8     1.000000\n",
       "column_cos_9     1.000000\n",
       "target           9.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2.apply(max, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler  =  MinMaxScaler ()\n",
    "X = scaler.fit_transform(train2.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X,\n",
    "train.iloc[:,-1], train_size=0.8, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=20, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "11302/11302 [==============================] - 2s 153us/step - loss: -3.4035 - acc: 0.2441\n",
      "Epoch 2/150\n",
      "11302/11302 [==============================] - 1s 123us/step - loss: -5.7351 - acc: 0.2462\n",
      "Epoch 3/150\n",
      "11302/11302 [==============================] - 1s 126us/step - loss: -5.9585 - acc: 0.2469\n",
      "Epoch 4/150\n",
      "11302/11302 [==============================] - 2s 139us/step - loss: -6.0612 - acc: 0.2429\n",
      "Epoch 5/150\n",
      "11302/11302 [==============================] - 1s 127us/step - loss: -6.0767 - acc: 0.2455\n",
      "Epoch 6/150\n",
      "11302/11302 [==============================] - 1s 128us/step - loss: -6.0898 - acc: 0.2426\n",
      "Epoch 7/150\n",
      "11302/11302 [==============================] - 1s 129us/step - loss: -6.0874 - acc: 0.2426\n",
      "Epoch 8/150\n",
      "11302/11302 [==============================] - 1s 126us/step - loss: -6.0816 - acc: 0.2432\n",
      "Epoch 9/150\n",
      "11302/11302 [==============================] - 1s 125us/step - loss: -6.0920 - acc: 0.2405\n",
      "Epoch 10/150\n",
      "11302/11302 [==============================] - 1s 123us/step - loss: -6.0979 - acc: 0.2429\n",
      "Epoch 11/150\n",
      "11302/11302 [==============================] - 1s 126us/step - loss: -6.0956 - acc: 0.2423\n",
      "Epoch 12/150\n",
      "11302/11302 [==============================] - 1s 125us/step - loss: -6.0941 - acc: 0.2443\n",
      "Epoch 13/150\n",
      "11302/11302 [==============================] - 2s 135us/step - loss: -6.0983 - acc: 0.2416\n",
      "Epoch 14/150\n",
      "11302/11302 [==============================] - 1s 125us/step - loss: -6.1089 - acc: 0.2434\n",
      "Epoch 15/150\n",
      "11302/11302 [==============================] - 1s 124us/step - loss: -6.0968 - acc: 0.2428\n",
      "Epoch 16/150\n",
      "11302/11302 [==============================] - 1s 123us/step - loss: -6.0939 - acc: 0.2413\n",
      "Epoch 17/150\n",
      "11302/11302 [==============================] - 2s 137us/step - loss: -6.0923 - acc: 0.2407\n",
      "Epoch 18/150\n",
      "11302/11302 [==============================] - 1s 125us/step - loss: -6.0913 - acc: 0.2423\n",
      "Epoch 19/150\n",
      "11302/11302 [==============================] - 1s 124us/step - loss: -6.0941 - acc: 0.2423\n",
      "Epoch 20/150\n",
      "11302/11302 [==============================] - 1s 124us/step - loss: -6.0971 - acc: 0.2402\n",
      "Epoch 21/150\n",
      "11302/11302 [==============================] - 1s 125us/step - loss: -6.1013 - acc: 0.2423\n",
      "Epoch 22/150\n",
      "11302/11302 [==============================] - 1s 124us/step - loss: -6.1073 - acc: 0.2419\n",
      "Epoch 23/150\n",
      "11302/11302 [==============================] - 1s 125us/step - loss: -6.1089 - acc: 0.2414\n",
      "Epoch 24/150\n",
      "11302/11302 [==============================] - 1s 127us/step - loss: -6.1053 - acc: 0.2418\n",
      "Epoch 25/150\n",
      "11302/11302 [==============================] - 1s 126us/step - loss: -6.1092 - acc: 0.2422\n",
      "Epoch 26/150\n",
      "11302/11302 [==============================] - 1s 126us/step - loss: -6.1153 - acc: 0.2433\n",
      "Epoch 27/150\n",
      "11302/11302 [==============================] - 1s 126us/step - loss: -6.1135 - acc: 0.2414\n",
      "Epoch 28/150\n",
      "11302/11302 [==============================] - 2s 142us/step - loss: -6.1171 - acc: 0.2430\n",
      "Epoch 29/150\n",
      "11302/11302 [==============================] - 2s 155us/step - loss: -6.1241 - acc: 0.2430\n",
      "Epoch 30/150\n",
      "11302/11302 [==============================] - 2s 153us/step - loss: -6.1206 - acc: 0.2410\n",
      "Epoch 31/150\n",
      "11302/11302 [==============================] - 2s 155us/step - loss: -6.1215 - acc: 0.2403\n",
      "Epoch 32/150\n",
      "11302/11302 [==============================] - 2s 140us/step - loss: -6.1211 - acc: 0.2424\n",
      "Epoch 33/150\n",
      "11302/11302 [==============================] - 1s 121us/step - loss: -6.1298 - acc: 0.2433\n",
      "Epoch 34/150\n",
      "11302/11302 [==============================] - 1s 122us/step - loss: -6.1282 - acc: 0.2431\n",
      "Epoch 35/150\n",
      "11302/11302 [==============================] - 2s 143us/step - loss: -6.1257 - acc: 0.2437\n",
      "Epoch 36/150\n",
      "11302/11302 [==============================] - 1s 120us/step - loss: -6.1334 - acc: 0.2418\n",
      "Epoch 37/150\n",
      "11302/11302 [==============================] - 1s 122us/step - loss: -6.1346 - acc: 0.2415\n",
      "Epoch 38/150\n",
      "11302/11302 [==============================] - 1s 121us/step - loss: -6.1397 - acc: 0.2419\n",
      "Epoch 39/150\n",
      "11302/11302 [==============================] - 1s 121us/step - loss: -6.1363 - acc: 0.2431\n",
      "Epoch 40/150\n",
      "11302/11302 [==============================] - 1s 121us/step - loss: -6.1442 - acc: 0.2400\n",
      "Epoch 41/150\n",
      "11302/11302 [==============================] - 1s 132us/step - loss: -6.1507 - acc: 0.2428\n",
      "Epoch 42/150\n",
      "11302/11302 [==============================] - 2s 150us/step - loss: -6.1435 - acc: 0.2458\n",
      "Epoch 43/150\n",
      "11302/11302 [==============================] - 2s 160us/step - loss: -6.1457 - acc: 0.2445\n",
      "Epoch 44/150\n",
      "11302/11302 [==============================] - 2s 149us/step - loss: -6.1560 - acc: 0.2427\n",
      "Epoch 45/150\n",
      "11302/11302 [==============================] - 1s 131us/step - loss: -6.1560 - acc: 0.2425\n",
      "Epoch 46/150\n",
      "11302/11302 [==============================] - 1s 129us/step - loss: -6.1602 - acc: 0.2407\n",
      "Epoch 47/150\n",
      "11302/11302 [==============================] - 2s 139us/step - loss: -6.1676 - acc: 0.2440\n",
      "Epoch 48/150\n",
      "11302/11302 [==============================] - 2s 142us/step - loss: -6.1551 - acc: 0.2448\n",
      "Epoch 49/150\n",
      "11302/11302 [==============================] - 2s 152us/step - loss: -6.1660 - acc: 0.2442\n",
      "Epoch 50/150\n",
      "11302/11302 [==============================] - 2s 163us/step - loss: -6.1656 - acc: 0.2426\n",
      "Epoch 51/150\n",
      "11302/11302 [==============================] - 2s 142us/step - loss: -6.1739 - acc: 0.2423\n",
      "Epoch 52/150\n",
      "11302/11302 [==============================] - 2s 200us/step - loss: -6.1842 - acc: 0.2446\n",
      "Epoch 53/150\n",
      "11302/11302 [==============================] - 2s 135us/step - loss: -6.1874 - acc: 0.2452\n",
      "Epoch 54/150\n",
      "11302/11302 [==============================] - 1s 129us/step - loss: -6.1952 - acc: 0.2448\n",
      "Epoch 55/150\n",
      "11302/11302 [==============================] - 1s 119us/step - loss: -6.2034 - acc: 0.2443\n",
      "Epoch 56/150\n",
      "11302/11302 [==============================] - 1s 130us/step - loss: -6.1872 - acc: 0.2451\n",
      "Epoch 57/150\n",
      "11302/11302 [==============================] - 1s 125us/step - loss: -6.2066 - acc: 0.2410\n",
      "Epoch 58/150\n",
      "11302/11302 [==============================] - 1s 121us/step - loss: -6.2110 - acc: 0.2426\n",
      "Epoch 59/150\n",
      "11302/11302 [==============================] - 1s 130us/step - loss: -6.2069 - acc: 0.2429\n",
      "Epoch 60/150\n",
      "11302/11302 [==============================] - 2s 152us/step - loss: -6.2196 - acc: 0.2444\n",
      "Epoch 61/150\n",
      "11302/11302 [==============================] - 2s 156us/step - loss: -6.2540 - acc: 0.2423\n",
      "Epoch 62/150\n",
      "11302/11302 [==============================] - 2s 142us/step - loss: -6.2487 - acc: 0.2434\n",
      "Epoch 63/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.2518 - acc: 0.2424\n",
      "Epoch 64/150\n",
      "11302/11302 [==============================] - 1s 125us/step - loss: -6.2685 - acc: 0.2430\n",
      "Epoch 65/150\n",
      "11302/11302 [==============================] - 1s 126us/step - loss: -6.2692 - acc: 0.2423\n",
      "Epoch 66/150\n",
      "11302/11302 [==============================] - 1s 122us/step - loss: -6.2844 - acc: 0.2435\n",
      "Epoch 67/150\n",
      "11302/11302 [==============================] - 1s 122us/step - loss: -6.3147 - acc: 0.2464\n",
      "Epoch 68/150\n",
      "11302/11302 [==============================] - 1s 124us/step - loss: -6.3062 - acc: 0.2396\n",
      "Epoch 69/150\n",
      "11302/11302 [==============================] - 1s 128us/step - loss: -6.3182 - acc: 0.2449\n",
      "Epoch 70/150\n",
      "11302/11302 [==============================] - 2s 151us/step - loss: -6.3182 - acc: 0.2448\n",
      "Epoch 71/150\n",
      "11302/11302 [==============================] - 1s 126us/step - loss: -6.3386 - acc: 0.2442\n",
      "Epoch 72/150\n",
      "11302/11302 [==============================] - 1s 122us/step - loss: -6.3355 - acc: 0.2437\n",
      "Epoch 73/150\n",
      "11302/11302 [==============================] - 1s 123us/step - loss: -6.3213 - acc: 0.2438\n",
      "Epoch 74/150\n",
      "11302/11302 [==============================] - 1s 125us/step - loss: -6.3646 - acc: 0.2438\n",
      "Epoch 75/150\n",
      "11302/11302 [==============================] - 1s 125us/step - loss: -6.3430 - acc: 0.2443\n",
      "Epoch 76/150\n",
      "11302/11302 [==============================] - 1s 124us/step - loss: -6.3440 - acc: 0.2442\n",
      "Epoch 77/150\n",
      "11302/11302 [==============================] - 1s 132us/step - loss: -6.3601 - acc: 0.2439\n",
      "Epoch 78/150\n",
      "11302/11302 [==============================] - 1s 126us/step - loss: -6.3511 - acc: 0.2453\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11302/11302 [==============================] - 1s 123us/step - loss: -6.3708 - acc: 0.2425\n",
      "Epoch 80/150\n",
      "11302/11302 [==============================] - 1s 122us/step - loss: -6.3534 - acc: 0.2438\n",
      "Epoch 81/150\n",
      "11302/11302 [==============================] - 1s 123us/step - loss: -6.3943 - acc: 0.2444\n",
      "Epoch 82/150\n",
      "11302/11302 [==============================] - 1s 120us/step - loss: -6.3663 - acc: 0.2429\n",
      "Epoch 83/150\n",
      "11302/11302 [==============================] - 1s 119us/step - loss: -6.3924 - acc: 0.2436\n",
      "Epoch 84/150\n",
      "11302/11302 [==============================] - 1s 119us/step - loss: -6.3830 - acc: 0.2435\n",
      "Epoch 85/150\n",
      "11302/11302 [==============================] - 1s 118us/step - loss: -6.3821 - acc: 0.2416\n",
      "Epoch 86/150\n",
      "11302/11302 [==============================] - 1s 118us/step - loss: -6.4005 - acc: 0.2424\n",
      "Epoch 87/150\n",
      "11302/11302 [==============================] - 1s 119us/step - loss: -6.4152 - acc: 0.2431\n",
      "Epoch 88/150\n",
      "11302/11302 [==============================] - 2s 140us/step - loss: -6.4094 - acc: 0.2412\n",
      "Epoch 89/150\n",
      "11302/11302 [==============================] - 1s 125us/step - loss: -6.4076 - acc: 0.2416\n",
      "Epoch 90/150\n",
      "11302/11302 [==============================] - 1s 120us/step - loss: -6.3883 - acc: 0.2423\n",
      "Epoch 91/150\n",
      "11302/11302 [==============================] - 1s 119us/step - loss: -6.3995 - acc: 0.2429\n",
      "Epoch 92/150\n",
      "11302/11302 [==============================] - 1s 120us/step - loss: -6.4090 - acc: 0.2449\n",
      "Epoch 93/150\n",
      "11302/11302 [==============================] - 1s 120us/step - loss: -6.3981 - acc: 0.2421\n",
      "Epoch 94/150\n",
      "11302/11302 [==============================] - 1s 120us/step - loss: -6.4147 - acc: 0.2396\n",
      "Epoch 95/150\n",
      "11302/11302 [==============================] - 1s 120us/step - loss: -6.4127 - acc: 0.2425\n",
      "Epoch 96/150\n",
      "11302/11302 [==============================] - 1s 122us/step - loss: -6.4197 - acc: 0.2409\n",
      "Epoch 97/150\n",
      "11302/11302 [==============================] - 1s 120us/step - loss: -6.4223 - acc: 0.2431\n",
      "Epoch 98/150\n",
      "11302/11302 [==============================] - 1s 120us/step - loss: -6.4026 - acc: 0.2416\n",
      "Epoch 99/150\n",
      "11302/11302 [==============================] - 1s 119us/step - loss: -6.4325 - acc: 0.2451\n",
      "Epoch 100/150\n",
      "11302/11302 [==============================] - 1s 120us/step - loss: -6.4194 - acc: 0.2415\n",
      "Epoch 101/150\n",
      "11302/11302 [==============================] - 1s 120us/step - loss: -6.4608 - acc: 0.2409\n",
      "Epoch 102/150\n",
      "11302/11302 [==============================] - 1s 120us/step - loss: -6.4085 - acc: 0.2403\n",
      "Epoch 103/150\n",
      "11302/11302 [==============================] - 1s 120us/step - loss: -6.4056 - acc: 0.2409\n",
      "Epoch 104/150\n",
      "11302/11302 [==============================] - 1s 122us/step - loss: -6.4307 - acc: 0.2432\n",
      "Epoch 105/150\n",
      "11302/11302 [==============================] - 1s 119us/step - loss: -6.4582 - acc: 0.2412\n",
      "Epoch 106/150\n",
      "11302/11302 [==============================] - 1s 118us/step - loss: -6.4381 - acc: 0.2401\n",
      "Epoch 107/150\n",
      "11302/11302 [==============================] - 1s 121us/step - loss: -6.4025 - acc: 0.2420\n",
      "Epoch 108/150\n",
      "11302/11302 [==============================] - 2s 139us/step - loss: -6.4438 - acc: 0.2423\n",
      "Epoch 109/150\n",
      "11302/11302 [==============================] - 1s 122us/step - loss: -6.4299 - acc: 0.2424\n",
      "Epoch 110/150\n",
      "11302/11302 [==============================] - 1s 124us/step - loss: -6.4468 - acc: 0.2396\n",
      "Epoch 111/150\n",
      "11302/11302 [==============================] - 1s 118us/step - loss: -6.4448 - acc: 0.2419\n",
      "Epoch 112/150\n",
      "11302/11302 [==============================] - 1s 119us/step - loss: -6.4700 - acc: 0.2431\n",
      "Epoch 113/150\n",
      "11302/11302 [==============================] - 1s 119us/step - loss: -6.4183 - acc: 0.2396\n",
      "Epoch 114/150\n",
      "11302/11302 [==============================] - 1s 119us/step - loss: -6.4135 - acc: 0.2408\n",
      "Epoch 115/150\n",
      "11302/11302 [==============================] - 1s 120us/step - loss: -6.4377 - acc: 0.2420\n",
      "Epoch 116/150\n",
      "11302/11302 [==============================] - 1s 120us/step - loss: -6.4637 - acc: 0.2398\n",
      "Epoch 117/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.4358 - acc: 0.2413\n",
      "Epoch 118/150\n",
      "11302/11302 [==============================] - 2s 155us/step - loss: -6.4327 - acc: 0.2410\n",
      "Epoch 119/150\n",
      "11302/11302 [==============================] - 2s 135us/step - loss: -6.4530 - acc: 0.2400\n",
      "Epoch 120/150\n",
      "11302/11302 [==============================] - 1s 130us/step - loss: -6.4399 - acc: 0.2421\n",
      "Epoch 121/150\n",
      "11302/11302 [==============================] - 1s 130us/step - loss: -6.4527 - acc: 0.2421\n",
      "Epoch 122/150\n",
      "11302/11302 [==============================] - 1s 131us/step - loss: -6.4417 - acc: 0.2377\n",
      "Epoch 123/150\n",
      "11302/11302 [==============================] - 1s 130us/step - loss: -6.4799 - acc: 0.2384\n",
      "Epoch 124/150\n",
      "11302/11302 [==============================] - 1s 130us/step - loss: -6.4325 - acc: 0.2410\n",
      "Epoch 125/150\n",
      "11302/11302 [==============================] - 2s 143us/step - loss: -6.4513 - acc: 0.2382\n",
      "Epoch 126/150\n",
      "11302/11302 [==============================] - 2s 154us/step - loss: -6.4562 - acc: 0.2385\n",
      "Epoch 127/150\n",
      "11302/11302 [==============================] - 2s 135us/step - loss: -6.4564 - acc: 0.2387\n",
      "Epoch 128/150\n",
      "11302/11302 [==============================] - 1s 130us/step - loss: -6.4560 - acc: 0.2435\n",
      "Epoch 129/150\n",
      "11302/11302 [==============================] - 1s 130us/step - loss: -6.4173 - acc: 0.2407\n",
      "Epoch 130/150\n",
      "11302/11302 [==============================] - 2s 137us/step - loss: -6.4377 - acc: 0.2422\n",
      "Epoch 131/150\n",
      "11302/11302 [==============================] - 2s 137us/step - loss: -6.4641 - acc: 0.2387\n",
      "Epoch 132/150\n",
      "11302/11302 [==============================] - 1s 126us/step - loss: -6.4942 - acc: 0.2424\n",
      "Epoch 133/150\n",
      "11302/11302 [==============================] - 1s 124us/step - loss: -6.4496 - acc: 0.2409\n",
      "Epoch 134/150\n",
      "11302/11302 [==============================] - 1s 124us/step - loss: -6.4608 - acc: 0.2408\n",
      "Epoch 135/150\n",
      "11302/11302 [==============================] - 1s 125us/step - loss: -6.4205 - acc: 0.2427\n",
      "Epoch 136/150\n",
      "11302/11302 [==============================] - 1s 123us/step - loss: -6.4500 - acc: 0.2408\n",
      "Epoch 137/150\n",
      "11302/11302 [==============================] - 1s 127us/step - loss: -6.4387 - acc: 0.2402\n",
      "Epoch 138/150\n",
      "11302/11302 [==============================] - 1s 126us/step - loss: -6.3939 - acc: 0.2419\n",
      "Epoch 139/150\n",
      "11302/11302 [==============================] - 1s 123us/step - loss: -6.4575 - acc: 0.2420\n",
      "Epoch 140/150\n",
      "11302/11302 [==============================] - 1s 125us/step - loss: -6.4392 - acc: 0.2405\n",
      "Epoch 141/150\n",
      "11302/11302 [==============================] - 1s 125us/step - loss: -6.4239 - acc: 0.2431\n",
      "Epoch 142/150\n",
      "11302/11302 [==============================] - 1s 123us/step - loss: -6.4449 - acc: 0.2408\n",
      "Epoch 143/150\n",
      "11302/11302 [==============================] - 2s 144us/step - loss: -6.2559 - acc: 0.2418\n",
      "Epoch 144/150\n",
      "11302/11302 [==============================] - 2s 165us/step - loss: -6.4207 - acc: 0.2453\n",
      "Epoch 145/150\n",
      "11302/11302 [==============================] - 2s 133us/step - loss: -6.4596 - acc: 0.2425\n",
      "Epoch 146/150\n",
      "11302/11302 [==============================] - 2s 133us/step - loss: -6.4710 - acc: 0.2396\n",
      "Epoch 147/150\n",
      "11302/11302 [==============================] - 1s 131us/step - loss: -6.3677 - acc: 0.2425\n",
      "Epoch 148/150\n",
      "11302/11302 [==============================] - 1s 131us/step - loss: -6.4398 - acc: 0.2404\n",
      "Epoch 149/150\n",
      "11302/11302 [==============================] - 1s 131us/step - loss: -6.4622 - acc: 0.2429\n",
      "Epoch 150/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.5028 - acc: 0.2414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff75fd754a8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(train_x, train_y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2826/2826 [==============================] - 0s 44us/step\n",
      "\n",
      "acc: 25.37%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(test_x, test_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network with Root Match feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.read_csv(\"train_detect_sent.csv\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predicted[predicted[\"sentences\"].apply(lambda x: len(ast.literal_eval(x)))<11].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_from_root(train):\n",
    "    \n",
    "    for i in range(train.shape[0]):\n",
    "        if len(ast.literal_eval(train[\"root_match_idx\"][i])) == 0: pass\n",
    "        \n",
    "        else:\n",
    "            for item in ast.literal_eval(train[\"root_match_idx\"][i]):\n",
    "                train.loc[i, \"column_root_\"+\"%s\"%item] = 1\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = get_columns_from_root(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset3 = predicted[[\"column_root_0\",\"column_root_1\",\"column_root_2\",\"column_root_3\",\"column_root_4\",\"column_root_5\",\\\n",
    "             \"column_root_6\",\"column_root_7\",\"column_root_8\",\"column_root_9\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/Documents/programming/mybot/mybotenv/lib/python3.5/site-packages/pandas/core/frame.py:3790: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "subset3.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = pd.concat([subset3, train2],axis=1, join_axes=[subset3.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = train3[[\"column_root_0\",\"column_root_1\",\"column_root_2\",\"column_root_3\",\"column_root_4\",\"column_root_5\",\\\n",
    "             \"column_root_6\",\"column_root_7\",\"column_root_8\",\"column_root_9\", \"column_cos_0\",\"column_cos_1\",\\\n",
    "           \"column_cos_2\",\"column_cos_3\",\"column_cos_4\",\"column_cos_5\",\\\n",
    "             \"column_cos_6\",\"column_cos_7\",\"column_cos_8\",\"column_cos_9\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_root_0</th>\n",
       "      <th>column_root_1</th>\n",
       "      <th>column_root_2</th>\n",
       "      <th>column_root_3</th>\n",
       "      <th>column_root_4</th>\n",
       "      <th>column_root_5</th>\n",
       "      <th>column_root_6</th>\n",
       "      <th>column_root_7</th>\n",
       "      <th>column_root_8</th>\n",
       "      <th>column_root_9</th>\n",
       "      <th>...</th>\n",
       "      <th>column_cos_1</th>\n",
       "      <th>column_cos_2</th>\n",
       "      <th>column_cos_3</th>\n",
       "      <th>column_cos_4</th>\n",
       "      <th>column_cos_5</th>\n",
       "      <th>column_cos_6</th>\n",
       "      <th>column_cos_7</th>\n",
       "      <th>column_cos_8</th>\n",
       "      <th>column_cos_9</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117768</td>\n",
       "      <td>0.099913</td>\n",
       "      <td>0.122374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086653</td>\n",
       "      <td>0.073723</td>\n",
       "      <td>0.101862</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068415</td>\n",
       "      <td>0.072894</td>\n",
       "      <td>0.072626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092791</td>\n",
       "      <td>0.081222</td>\n",
       "      <td>0.109342</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103141</td>\n",
       "      <td>0.087416</td>\n",
       "      <td>0.108193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   column_root_0  column_root_1  column_root_2  column_root_3  column_root_4  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2            0.0            0.0            0.0            0.0            0.0   \n",
       "3            0.0            1.0            0.0            1.0            0.0   \n",
       "4            0.0            1.0            0.0            1.0            0.0   \n",
       "\n",
       "   column_root_5  column_root_6  column_root_7  column_root_8  column_root_9  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2            0.0            0.0            0.0            0.0            0.0   \n",
       "3            0.0            0.0            0.0            0.0            0.0   \n",
       "4            0.0            0.0            0.0            0.0            0.0   \n",
       "\n",
       "    ...    column_cos_1  column_cos_2  column_cos_3  column_cos_4  \\\n",
       "0   ...        0.117768      0.099913      0.122374           1.0   \n",
       "1   ...        0.086653      0.073723      0.101862           1.0   \n",
       "2   ...        0.068415      0.072894      0.072626           1.0   \n",
       "3   ...        0.092791      0.081222      0.109342           1.0   \n",
       "4   ...        0.103141      0.087416      0.108193           1.0   \n",
       "\n",
       "   column_cos_5  column_cos_6  column_cos_7  column_cos_8  column_cos_9  \\\n",
       "0           1.0           1.0           1.0           1.0           1.0   \n",
       "1           1.0           1.0           1.0           1.0           1.0   \n",
       "2           1.0           1.0           1.0           1.0           1.0   \n",
       "3           1.0           1.0           1.0           1.0           1.0   \n",
       "4           1.0           1.0           1.0           1.0           1.0   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       3  \n",
       "3       1  \n",
       "4       1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(train3.iloc[:,:-1],\n",
    "train3.iloc[:,-1], train_size=0.8, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=20, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "11302/11302 [==============================] - 3s 258us/step - loss: -3.3385 - acc: 0.2430\n",
      "Epoch 2/150\n",
      "11302/11302 [==============================] - 1s 132us/step - loss: -6.1532 - acc: 0.2501\n",
      "Epoch 3/150\n",
      "11302/11302 [==============================] - 2s 133us/step - loss: -6.2485 - acc: 0.2536\n",
      "Epoch 4/150\n",
      "11302/11302 [==============================] - 1s 132us/step - loss: -6.2898 - acc: 0.2522\n",
      "Epoch 5/150\n",
      "11302/11302 [==============================] - 2s 149us/step - loss: -6.3216 - acc: 0.2540\n",
      "Epoch 6/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.3489 - acc: 0.2517\n",
      "Epoch 7/150\n",
      "11302/11302 [==============================] - 2s 135us/step - loss: -6.3411 - acc: 0.2539\n",
      "Epoch 8/150\n",
      "11302/11302 [==============================] - 2s 146us/step - loss: -6.3619 - acc: 0.2531\n",
      "Epoch 9/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.3610 - acc: 0.2535\n",
      "Epoch 10/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.3727 - acc: 0.2541\n",
      "Epoch 11/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.3761 - acc: 0.2555\n",
      "Epoch 12/150\n",
      "11302/11302 [==============================] - 2s 140us/step - loss: -6.3772 - acc: 0.2542\n",
      "Epoch 13/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.3854 - acc: 0.2559\n",
      "Epoch 14/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.3825 - acc: 0.2536\n",
      "Epoch 15/150\n",
      "11302/11302 [==============================] - 2s 137us/step - loss: -6.3787 - acc: 0.2523\n",
      "Epoch 16/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.3859 - acc: 0.2550\n",
      "Epoch 17/150\n",
      "11302/11302 [==============================] - 2s 152us/step - loss: -6.3967 - acc: 0.2508\n",
      "Epoch 18/150\n",
      "11302/11302 [==============================] - 2s 137us/step - loss: -6.3959 - acc: 0.2515\n",
      "Epoch 19/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.4030 - acc: 0.2528\n",
      "Epoch 20/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.4014 - acc: 0.2527\n",
      "Epoch 21/150\n",
      "11302/11302 [==============================] - 2s 135us/step - loss: -6.4019 - acc: 0.2530\n",
      "Epoch 22/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.4009 - acc: 0.2521\n",
      "Epoch 23/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.4007 - acc: 0.2511\n",
      "Epoch 24/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.4109 - acc: 0.2512\n",
      "Epoch 25/150\n",
      "11302/11302 [==============================] - 2s 135us/step - loss: -6.4192 - acc: 0.2530\n",
      "Epoch 26/150\n",
      "11302/11302 [==============================] - 2s 133us/step - loss: -6.4252 - acc: 0.2521\n",
      "Epoch 27/150\n",
      "11302/11302 [==============================] - 2s 133us/step - loss: -6.4099 - acc: 0.2494\n",
      "Epoch 28/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.4256 - acc: 0.2537\n",
      "Epoch 29/150\n",
      "11302/11302 [==============================] - 2s 137us/step - loss: -6.4299 - acc: 0.2544\n",
      "Epoch 30/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.4252 - acc: 0.2488\n",
      "Epoch 31/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.4360 - acc: 0.2544\n",
      "Epoch 32/150\n",
      "11302/11302 [==============================] - 2s 135us/step - loss: -6.4360 - acc: 0.2526\n",
      "Epoch 33/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.4413 - acc: 0.2504\n",
      "Epoch 34/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.4516 - acc: 0.2528\n",
      "Epoch 35/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.4575 - acc: 0.2524\n",
      "Epoch 36/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.4503 - acc: 0.2527\n",
      "Epoch 37/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.4574 - acc: 0.2525\n",
      "Epoch 38/150\n",
      "11302/11302 [==============================] - 2s 156us/step - loss: -6.4618 - acc: 0.2523\n",
      "Epoch 39/150\n",
      "11302/11302 [==============================] - 2s 158us/step - loss: -6.4696 - acc: 0.2503\n",
      "Epoch 40/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.4691 - acc: 0.2520\n",
      "Epoch 41/150\n",
      "11302/11302 [==============================] - 2s 135us/step - loss: -6.4627 - acc: 0.2504\n",
      "Epoch 42/150\n",
      "11302/11302 [==============================] - 2s 141us/step - loss: -6.4734 - acc: 0.2502\n",
      "Epoch 43/150\n",
      "11302/11302 [==============================] - 2s 150us/step - loss: -6.4841 - acc: 0.2532\n",
      "Epoch 44/150\n",
      "11302/11302 [==============================] - 2s 143us/step - loss: -6.4851 - acc: 0.2541\n",
      "Epoch 45/150\n",
      "11302/11302 [==============================] - 2s 138us/step - loss: -6.4742 - acc: 0.2542\n",
      "Epoch 46/150\n",
      "11302/11302 [==============================] - 2s 138us/step - loss: -6.4794 - acc: 0.2514\n",
      "Epoch 47/150\n",
      "11302/11302 [==============================] - 2s 138us/step - loss: -6.4940 - acc: 0.2508\n",
      "Epoch 48/150\n",
      "11302/11302 [==============================] - 2s 145us/step - loss: -6.4919 - acc: 0.2523\n",
      "Epoch 49/150\n",
      "11302/11302 [==============================] - 2s 147us/step - loss: -6.5030 - acc: 0.2530\n",
      "Epoch 50/150\n",
      "11302/11302 [==============================] - 2s 145us/step - loss: -6.4996 - acc: 0.2537\n",
      "Epoch 51/150\n",
      "11302/11302 [==============================] - 2s 145us/step - loss: -6.5088 - acc: 0.2534\n",
      "Epoch 52/150\n",
      "11302/11302 [==============================] - 2s 149us/step - loss: -6.5197 - acc: 0.2546\n",
      "Epoch 53/150\n",
      "11302/11302 [==============================] - 2s 145us/step - loss: -6.5101 - acc: 0.2538\n",
      "Epoch 54/150\n",
      "11302/11302 [==============================] - 2s 147us/step - loss: -6.5149 - acc: 0.2542\n",
      "Epoch 55/150\n",
      "11302/11302 [==============================] - 2s 143us/step - loss: -6.5160 - acc: 0.2502\n",
      "Epoch 56/150\n",
      "11302/11302 [==============================] - 2s 139us/step - loss: -6.5071 - acc: 0.2508\n",
      "Epoch 57/150\n",
      "11302/11302 [==============================] - 1s 132us/step - loss: -6.5247 - acc: 0.2523\n",
      "Epoch 58/150\n",
      "11302/11302 [==============================] - 1s 133us/step - loss: -6.5384 - acc: 0.2529\n",
      "Epoch 59/150\n",
      "11302/11302 [==============================] - 1s 129us/step - loss: -6.5259 - acc: 0.2523\n",
      "Epoch 60/150\n",
      "11302/11302 [==============================] - 2s 138us/step - loss: -6.5281 - acc: 0.2530\n",
      "Epoch 61/150\n",
      "11302/11302 [==============================] - 2s 149us/step - loss: -6.5356 - acc: 0.2542\n",
      "Epoch 62/150\n",
      "11302/11302 [==============================] - 2s 146us/step - loss: -6.5435 - acc: 0.2532\n",
      "Epoch 63/150\n",
      "11302/11302 [==============================] - 2s 147us/step - loss: -6.5293 - acc: 0.2523\n",
      "Epoch 64/150\n",
      "11302/11302 [==============================] - 2s 140us/step - loss: -6.5471 - acc: 0.2513\n",
      "Epoch 65/150\n",
      "11302/11302 [==============================] - 2s 142us/step - loss: -6.5528 - acc: 0.2515\n",
      "Epoch 66/150\n",
      "11302/11302 [==============================] - 2s 142us/step - loss: -6.5417 - acc: 0.2531\n",
      "Epoch 67/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.5681 - acc: 0.2538\n",
      "Epoch 68/150\n",
      "11302/11302 [==============================] - 1s 132us/step - loss: -6.5593 - acc: 0.2501\n",
      "Epoch 69/150\n",
      "11302/11302 [==============================] - 2s 153us/step - loss: -6.5573 - acc: 0.2532\n",
      "Epoch 70/150\n",
      "11302/11302 [==============================] - 2s 135us/step - loss: -6.5609 - acc: 0.2515\n",
      "Epoch 71/150\n",
      "11302/11302 [==============================] - 2s 175us/step - loss: -6.5635 - acc: 0.2523\n",
      "Epoch 72/150\n",
      "11302/11302 [==============================] - 2s 172us/step - loss: -6.5600 - acc: 0.2506\n",
      "Epoch 73/150\n",
      "11302/11302 [==============================] - 2s 153us/step - loss: -6.5645 - acc: 0.2514\n",
      "Epoch 74/150\n",
      "11302/11302 [==============================] - 2s 157us/step - loss: -6.5718 - acc: 0.2528\n",
      "Epoch 75/150\n",
      "11302/11302 [==============================] - 2s 150us/step - loss: -6.5768 - acc: 0.2502\n",
      "Epoch 76/150\n",
      "11302/11302 [==============================] - 2s 148us/step - loss: -6.5788 - acc: 0.2531\n",
      "Epoch 77/150\n",
      "11302/11302 [==============================] - 2s 152us/step - loss: -6.5905 - acc: 0.2525\n",
      "Epoch 78/150\n",
      "11302/11302 [==============================] - 2s 144us/step - loss: -6.5715 - acc: 0.2531\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11302/11302 [==============================] - 2s 137us/step - loss: -6.5826 - acc: 0.2511\n",
      "Epoch 80/150\n",
      "11302/11302 [==============================] - 2s 142us/step - loss: -6.5843 - acc: 0.2532\n",
      "Epoch 81/150\n",
      "11302/11302 [==============================] - 2s 142us/step - loss: -6.5887 - acc: 0.2515\n",
      "Epoch 82/150\n",
      "11302/11302 [==============================] - 2s 133us/step - loss: -6.5899 - acc: 0.2509\n",
      "Epoch 83/150\n",
      "11302/11302 [==============================] - 2s 150us/step - loss: -6.5960 - acc: 0.2534\n",
      "Epoch 84/150\n",
      "11302/11302 [==============================] - 2s 135us/step - loss: -6.5909 - acc: 0.2527\n",
      "Epoch 85/150\n",
      "11302/11302 [==============================] - 2s 135us/step - loss: -6.5797 - acc: 0.2520\n",
      "Epoch 86/150\n",
      "11302/11302 [==============================] - 1s 130us/step - loss: -6.6066 - acc: 0.2545\n",
      "Epoch 87/150\n",
      "11302/11302 [==============================] - 1s 131us/step - loss: -6.6011 - acc: 0.2544\n",
      "Epoch 88/150\n",
      "11302/11302 [==============================] - 2s 140us/step - loss: -6.6028 - acc: 0.2546\n",
      "Epoch 89/150\n",
      "11302/11302 [==============================] - 2s 145us/step - loss: -6.6138 - acc: 0.2529\n",
      "Epoch 90/150\n",
      "11302/11302 [==============================] - 2s 155us/step - loss: -6.6107 - acc: 0.2547\n",
      "Epoch 91/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.6013 - acc: 0.2524\n",
      "Epoch 92/150\n",
      "11302/11302 [==============================] - 1s 127us/step - loss: -6.6112 - acc: 0.2532\n",
      "Epoch 93/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.6269 - acc: 0.2523\n",
      "Epoch 94/150\n",
      "11302/11302 [==============================] - 2s 140us/step - loss: -6.6201 - acc: 0.2546\n",
      "Epoch 95/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.6211 - acc: 0.2541\n",
      "Epoch 96/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.6194 - acc: 0.2535\n",
      "Epoch 97/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.6282 - acc: 0.2541\n",
      "Epoch 98/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.6396 - acc: 0.2562\n",
      "Epoch 99/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.6401 - acc: 0.2545\n",
      "Epoch 100/150\n",
      "11302/11302 [==============================] - 2s 137us/step - loss: -6.6295 - acc: 0.2539\n",
      "Epoch 101/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.6373 - acc: 0.2549\n",
      "Epoch 102/150\n",
      "11302/11302 [==============================] - 2s 138us/step - loss: -6.6346 - acc: 0.2538\n",
      "Epoch 103/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.6476 - acc: 0.2535\n",
      "Epoch 104/150\n",
      "11302/11302 [==============================] - 2s 145us/step - loss: -6.6602 - acc: 0.2541\n",
      "Epoch 105/150\n",
      "11302/11302 [==============================] - 2s 138us/step - loss: -6.6483 - acc: 0.2531\n",
      "Epoch 106/150\n",
      "11302/11302 [==============================] - 2s 139us/step - loss: -6.6625 - acc: 0.2547\n",
      "Epoch 107/150\n",
      "11302/11302 [==============================] - 2s 135us/step - loss: -6.6710 - acc: 0.2520\n",
      "Epoch 108/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.6662 - acc: 0.2565\n",
      "Epoch 109/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.6521 - acc: 0.2526\n",
      "Epoch 110/150\n",
      "11302/11302 [==============================] - 2s 133us/step - loss: -6.6619 - acc: 0.2558\n",
      "Epoch 111/150\n",
      "11302/11302 [==============================] - 1s 129us/step - loss: -6.6662 - acc: 0.2530\n",
      "Epoch 112/150\n",
      "11302/11302 [==============================] - 2s 138us/step - loss: -6.6741 - acc: 0.2536\n",
      "Epoch 113/150\n",
      "11302/11302 [==============================] - 1s 130us/step - loss: -6.6760 - acc: 0.2550\n",
      "Epoch 114/150\n",
      "11302/11302 [==============================] - 2s 138us/step - loss: -6.6867 - acc: 0.2536\n",
      "Epoch 115/150\n",
      "11302/11302 [==============================] - 2s 140us/step - loss: -6.6847 - acc: 0.2543\n",
      "Epoch 116/150\n",
      "11302/11302 [==============================] - 2s 142us/step - loss: -6.6789 - acc: 0.2552\n",
      "Epoch 117/150\n",
      "11302/11302 [==============================] - 2s 134us/step - loss: -6.6869 - acc: 0.2564\n",
      "Epoch 118/150\n",
      "11302/11302 [==============================] - 2s 141us/step - loss: -6.6906 - acc: 0.2542\n",
      "Epoch 119/150\n",
      "11302/11302 [==============================] - 2s 139us/step - loss: -6.6859 - acc: 0.2535\n",
      "Epoch 120/150\n",
      "11302/11302 [==============================] - 2s 141us/step - loss: -6.6887 - acc: 0.2560\n",
      "Epoch 121/150\n",
      "11302/11302 [==============================] - 2s 140us/step - loss: -6.6842 - acc: 0.2536\n",
      "Epoch 122/150\n",
      "11302/11302 [==============================] - 1s 130us/step - loss: -6.6807 - acc: 0.2537\n",
      "Epoch 123/150\n",
      "11302/11302 [==============================] - 1s 116us/step - loss: -6.6731 - acc: 0.2539\n",
      "Epoch 124/150\n",
      "11302/11302 [==============================] - 1s 112us/step - loss: -6.6999 - acc: 0.2552\n",
      "Epoch 125/150\n",
      "11302/11302 [==============================] - 2s 140us/step - loss: -6.6830 - acc: 0.2524\n",
      "Epoch 126/150\n",
      "11302/11302 [==============================] - 2s 140us/step - loss: -6.6950 - acc: 0.2553\n",
      "Epoch 127/150\n",
      "11302/11302 [==============================] - 2s 141us/step - loss: -6.7069 - acc: 0.2560\n",
      "Epoch 128/150\n",
      "11302/11302 [==============================] - 1s 131us/step - loss: -6.6928 - acc: 0.2540\n",
      "Epoch 129/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.7002 - acc: 0.2538\n",
      "Epoch 130/150\n",
      "11302/11302 [==============================] - 2s 143us/step - loss: -6.6937 - acc: 0.2545\n",
      "Epoch 131/150\n",
      "11302/11302 [==============================] - 2s 146us/step - loss: -6.7264 - acc: 0.2562\n",
      "Epoch 132/150\n",
      "11302/11302 [==============================] - 2s 141us/step - loss: -6.7066 - acc: 0.2539\n",
      "Epoch 133/150\n",
      "11302/11302 [==============================] - 2s 138us/step - loss: -6.7131 - acc: 0.2550\n",
      "Epoch 134/150\n",
      "11302/11302 [==============================] - 2s 137us/step - loss: -6.7270 - acc: 0.2555\n",
      "Epoch 135/150\n",
      "11302/11302 [==============================] - 2s 138us/step - loss: -6.7101 - acc: 0.2562\n",
      "Epoch 136/150\n",
      "11302/11302 [==============================] - 2s 136us/step - loss: -6.6932 - acc: 0.2554\n",
      "Epoch 137/150\n",
      "11302/11302 [==============================] - 2s 145us/step - loss: -6.7124 - acc: 0.2545\n",
      "Epoch 138/150\n",
      "11302/11302 [==============================] - 1s 131us/step - loss: -6.7207 - acc: 0.2526\n",
      "Epoch 139/150\n",
      "11302/11302 [==============================] - 2s 146us/step - loss: -6.6955 - acc: 0.2563\n",
      "Epoch 140/150\n",
      "11302/11302 [==============================] - 2s 141us/step - loss: -6.7215 - acc: 0.2551\n",
      "Epoch 141/150\n",
      "11302/11302 [==============================] - 2s 152us/step - loss: -6.7112 - acc: 0.2537\n",
      "Epoch 142/150\n",
      "11302/11302 [==============================] - 2s 157us/step - loss: -6.7178 - acc: 0.2558\n",
      "Epoch 143/150\n",
      "11302/11302 [==============================] - 2s 149us/step - loss: -6.7197 - acc: 0.2530\n",
      "Epoch 144/150\n",
      "11302/11302 [==============================] - 2s 143us/step - loss: -6.7132 - acc: 0.2551\n",
      "Epoch 145/150\n",
      "11302/11302 [==============================] - 2s 150us/step - loss: -6.7351 - acc: 0.2541\n",
      "Epoch 146/150\n",
      "11302/11302 [==============================] - 2s 152us/step - loss: -6.7265 - acc: 0.2558\n",
      "Epoch 147/150\n",
      "11302/11302 [==============================] - 2s 161us/step - loss: -6.7121 - acc: 0.2563\n",
      "Epoch 148/150\n",
      "11302/11302 [==============================] - 2s 145us/step - loss: -6.7144 - acc: 0.2540\n",
      "Epoch 149/150\n",
      "11302/11302 [==============================] - 2s 159us/step - loss: -6.7243 - acc: 0.2543\n",
      "Epoch 150/150\n",
      "11302/11302 [==============================] - 2s 143us/step - loss: -6.7238 - acc: 0.2533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff75c4a4d68>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(train_x, train_y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2826/2826 [==============================] - 0s 64us/step\n",
      "\n",
      "acc: 26.33%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(test_x, test_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
